# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-4o

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use. ( configure in .env.local)
OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=10

# The time in milliseconds to wait for the stream to return a response.
STREAM_TIMEOUT=60000

# The name of the vector store provider.
VECTOR_STORE_PROVIDER=chroma

# The name of the collection in your Chroma database.
CHROMA_COLLECTION=default

# The name of the collection in your Chroma database for questions.
CHROMA_COLLECTION_QUESTIONS=questions

# The API endpoint for your Chroma database
# CHROMA_HOST=localhost

# The port for your Chroma database
# CHROMA_PORT=8000

# The local path to the Chroma database.
# Specify this if you are using a local Chroma database.
# Otherwise, use CHROMA_HOST and CHROMA_PORT config above
CHROMA_PATH="./chromadb"

# The name of the collection in your Qdrant database.
QDRANT_COLLECTION=default

# The url for your Qdrant database.
QDRANT_URL=

# Qdrant API key.
QDRANT_API_KEY=

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
# FILESERVER_URL_PREFIX=http://localhost:8000/api/files

# The address to start the backend app.
APP_HOST=localhost

# The port to start the backend app.
APP_PORT=5001

# The system prompt for the AI model.
SYSTEM_PROMPT=""

# Enabling reranker.
USE_RERANKER=false

# Cohere API key.
COHERE_API_KEY=

# Top K for Cohere.
COHERE_TOP_K=3

# Window size.
WINDOW_SIZE=3

# Enabling Sentence Window Retrieval.
USE_SENTENCE_WINDOW_RETRIEVAL=false

# The local path to the storage of generated images
IMG_STORAGE_DIR="generated_images"

# The name of image generation model to use.
IMG_GENERATION_MODEL=dall-e-2

# The number of images to be generated.
NO_OF_IMG=1

# The quality of images to be generated.
IMG_GENERATION_QUALITY=hd

# The size of images to be generated.
SIZE_OF_IMG=256x256

# The style of images to be generated.
STYLE_OF_IMG=natural
T_SYSTEMS_LLMHUB_BASE_URL='https://llm-server.llmhub.t-systems.net/v2'
OPENAI_API_VERSION='2024-02-01'
OLLAMA_REQUEST_TIMEOUT='120.0'
RERANK_PROVIDER='cohere'
USE_LLAMA_CLOUD='False'
LLAMA_CLOUD_INDEX_NAME=''
LLAMA_CLOUD_PROJECT_NAME=''

# Enabling ICL.
USE_ICL=false

# No. of similar questions.
NO_OF_SIMILAR_QUESIONS=3


# ICL supervised or not.
ICL_SUPERVISED=false

# Mongo URI.
MONGO_URI="mongodb://127.0.0.1:27017/"

# Mongo database.
MONGO_DB="EffectzGPT"

# Mongo collection.
MONGO_COLLECTION="QandA"

# Mongo document.
MONGO_DOCUMENT="sample_questions"

# Enabling RAPTOR.
USE_RAPTOR=false